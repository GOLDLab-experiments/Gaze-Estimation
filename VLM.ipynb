{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304457bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration\n",
    "from PIL import Image\n",
    "from hf_token import get_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da12b09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be95008b412a4eeeac5fed3929b0f0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(get_token())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e9495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92d9cf06f344c76adba4f5a851e7dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/700 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arbel\\AppData\\Roaming\\Python\\Python313\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\arbel\\.cache\\huggingface\\hub\\models--google--paligemma-3b-ft-textcaps-448. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a9bf3c59294df28fd67326e4e069a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/40.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ba8d71117e488b9165e631a7258311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.26M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e49272253474414b2a7a9f42645bcd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a207b5e5a9b74eae8f1529fc75d8722c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b60753082a4305b1d6f46d68a09853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/607 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259f98c3a6ca439ebbbe91ece7e57c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.09k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd15c0c8d8f45dca5ce2f6bc2de3e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/62.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f99966011f450ca6e4253a8ce473ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8ccbed6fe74e8b803a2faa3b2a1146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc88e9333544f7492e68a5055451e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d65a8bc9114a278f8c5f13f2780cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = 'google/paligemma-3b-ft-textcaps-448' # Fine-tuned for captioning\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id)\n",
    "\n",
    "model.to('cpu')\n",
    "print(\"Model loaded and moved to CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ccaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"test_image.jpg\" # <<< Replace with your image source\n",
    "image = Image.open(image_url).convert(\"RGB\")\n",
    "print(\"Image loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f56ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prompt is an attempt to guide the model, but its effectiveness is not guaranteed\n",
    "prompt = \"\"\"Analyze the person in the image. Consider their facial expression, any objects they are holding, and the surrounding environment.\n",
    "Based on these visual cues, classify their intent as either 'malicious', 'benign', or state if they appear to be a 'co-worker'.\n",
    "If they appear to be a co-worker, just state 'co-worker'.\n",
    "If their intent appears malicious, state 'malicious'.\n",
    "If their intent appears benign, state 'benign'.\n",
    "If you cannot determine, state 'uncertain'.\n",
    "Provide only one of these words as the answer.\"\"\"\n",
    "\n",
    "inputs = processor(text=prompt, images=image, return_tensors='pt')\n",
    "\n",
    "# Move inputs to CPU\n",
    "inputs = {k: v.to('cpu') for k, v in inputs.items()}\n",
    "print(\"Inputs processed and moved to CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea46c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1246765f2f43718fdb88b3ed611519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d44c280ec77458e964344333ad24569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   9%|8         | 482M/5.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e9a3ced5334b11976c0681f1075ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:  12%|#1        | 640M/5.56G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3d8eb7dbd54be59266609f1ecd1957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:  10%|9         | 545M/5.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the response\n",
    "# Use parameters that encourage a short, direct answer if possible\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=10, num_beams=1, do_sample=False) # Keeping generation short and deterministic\n",
    "response = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip().lower()\n",
    "\n",
    "print(\"Analysis Result:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
